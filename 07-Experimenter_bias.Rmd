# The experimenter as a source of bias

We have discussed numerous sources of bias that can occur in a study: systematic changes over time, use of inadequate measures, and inappropriate intervention groups. We now come to consider one further important factor: the experimenter.

The role of the experimenter was already alluded to in Chapter 7, where it was noted that some kinds of randomisation are problematic because they give the experimenter wiggle room to omit or include participants. You might imagine that no honest person would distort their study this way, but it is all too easy to provide a post hoc rationalisation for such decision. I realised this problem when I first tried to do a randomised trial myself. I was visiting a school to where we had recruited children for the study, and I was chatting to the children in their classroom. One little boy was overactive and seemed unable to concentrate for more than a minute or two on anything, yet he had met our criteria for study inclusion. I found myself fervently hoping he would not be in the intervention group! Fortunately, I had no control over this, and indeed, to this day I don't know if he was. 

## Allocation concealment

This brings us to the topic of masking, or allocation concealment about intervention status from the experimenter. Traditionally, the term 'blinding' has been used, but this is offensive to some visually impaired people, so I will avoid it here. Nevertheless, you may hear the term in the context of the 'double blind trial'. This refers to the situation when the neither the experimenter nor the participants are aware of who is in the active or the control group. As noted in chapter 4, it is seldom feasible to keep participants unaware of whether they are in an active intervention or control group, though use of active controls, as described in Chapter x, may allow for this.

In SLT practice, where resources are limited and the same person may be conducting the study and administering the intervention, particular care needs to be given to masking. A competent third party should be recruited to be responsible for allocation to intervention groups, but this is not all. It is also important to take steps to avoid experimenter bias in administration of baseline and outcome assessments. 

## The importance of masking for assessments

As discussed in Chapter 2, some assessments are more objective than others: it is relatively easy to be swayed by one's own desires and expectation when making a global rating of a person's communicative competence on a 4-point scale, much less so when administering a multiple choice comprehension test, where the participant selects a picture to match a named word. Nevertheless, there is ample evidence that, even with relatively objective tasks, experimenter bias can creep in. (Egs of people measuring wt/ht). 

Perhaps the most sobering example comes, not from an intervention study, but from data on a phonics screening test administered by teachers in UK schools in the years from xxxx to xxxx. The score is supposed to just indicate the number of items on a standard list of words and nonwords that a child reads accurately. Although there is some leeway in judging whether a nonword is correctly pronounced, this should not be expected to exert a big effect on final scores, given that teachers are provided with a list of acceptable pronunciations. The results, however, which are published annually on a government website, show clear evidence of scores being nudged up for some cases. We would expect a normal distribution of scores, but instead there is a sudden dip just below the pass mark and a corresponding excess of cases just about the pass mark. Since teachers were aware of the pass mark, they would have been able to nudge up the scores of children who were just one or two points below, and the distribution of scores is clear evidence that this happened. 

We don't usually think of teachers as dishonest or fraudulent. Some were opposed in principle to the phonics check and may have felt justified in not taking it seriously, but I suspect that most were doing their sincere best, but just did not think a slight tweak of a child's results would matter It's likely that many did not like the idea of categorising children as 'failing' at such a young age. And some may have been concerned that their personal reputation or that of their school might be damaged if too many children 'failed'. The possible reasons for 'nudging' are many, and cannot be established post hoc, but the point I want to stress is that this kind of behaviour is very common, not typically done in a deliberately dishonest fashion, but is something that will happen if people are motivated to get one result or another.

In medical trials, the large amount of evidence for experimenter bias on measures has led to a general consensus that it is vital that outcome assessments much be done by someone who is unaware of whether the participants was in the intervention or control group. This is likely to add to the cost of conducting a trial, but it gives security that no nudging has taken place.

## Conflict of interest 

Many medical journals, and increasingly journals in other fields, require author to declare conflicts of interest, and a statement to this effect is included with the published paper. Lo and Field (2009) define conflict of interest (COI) as:
"a set of circumstances that creates a risk that professional judgement or actions regarding a primary interest will be unduly influenced by a secondary interest”.
Typically, people think of COI as involving money. Someone who is marketing a computerised intervention, for instance, will be motivated to show it is effective – their business and livelihood would collapse if it was widely known to be useless. But COI – also sometimes referred to as 'competing interests' – extend beyond the realms of finance. 
-	A researcher's reputation may depend heavily on their invention of an intervention approach
-	A therapist may be aware of threats to cut government-funded services unless intervention is shown to be effective. 

For those in vocational professions such as therapy or teaching, relatively poor working conditions may be endured in return for a sense of doing good. An intervention study with null results can be hard to accept if it means that the value of one's daily work is challenged. 

In effect, most people involved in intervention studies want to show a positive effect for one reason or another. It's not generally possible to avoid all conflict of interest, but the important thing is to recognise experimenter bias as the rule rather than the exception, identify possible threats this poses to study validity, and  take stringent steps to counteract these.  I discussed above the ways in which results on outcome measures may be nudged up or down, often without any conscious attempt to mislead. But the impact of experimenter bias can occur at all stages of an intervention study:

-	At the stage of study design, the researcher may argue against including a control group – claiming ethical objections – because they are aware that it is much easier to show apparent intervention effects when there are no controls (see Chapter x)
-	In a controlled study, when allocating participants to intervention or control groups, the researcher may change inclusion criteria as the study progresses
-	Allocation to intervention or control groups may be under the control of a researcher who does not adopt truly random methods, and so can determine who is in which group. Chapter X explains how randomisation can overcome this.
-	As noted above, if the person doing baseline and outcome assessments knows which intervention group a participant is in, then scores may be nudged. This can be avoided by having assessments done by someone who is unaware of who got the intervention
-	When it comes to analysing the data, the researcher may decide on which variables to report, depending on the results. I discuss this problem and how to counteract it in Chapter x.
-	If the pattern of results does not show that the intervention is effective, then further checks and alternative analyses are conducted, whereas positive results are accepted without additional scrutiny 
-	If the trial gives disappointing results, then the decision may be made not to report them. See Chapter X for discussion of this problem and suggestions for avoiding it.

The important point to recognise is that being a good scientist often conflicts with our natural human tendencies. A good scientist is always objective, and interpretation of results is not swayed by personal likes and dislikes. On getting a positive intervention result, a good scientist will immediately ask: "Were there biases in my study that could have contributed to this finding?" – and indeed will not take offence if other scientists identify such factors. We need, of course, arguments in the opposite direction: a failure to see an intervention effect doesn't necessarily mean the intervention did not work – there could be aspects of study design that hide true effects, including too small a sample (see Chapter x). But I find that when I attend conferences where people discuss intervention studies, the question session is always dominated by people presenting arguments about why a null result may be misleading, but it is much rarer to hear people questioning the validity of a positive result. It is a human tendency to accept information that fits with our desires and prejudices (in this case, that intervention is effective) and to reject contrary evidence. It also goes against our human nature to be critical of an intervention study conducted by a well-intentioned person who has put in a great deal of time and effort. But at the end of the day it is the quality of the evidence, rather than the feelings of researchers, that must take priority. Currently, we still know rather little about how best to help children and adults who struggle with speech, language and communication. We will only change that if we take a rigorous and evidence-based approach to evaluating evidence.

## Class exercise

Once again, you need to find a published intervention study – this could be one you selected for a previous exercise, or a new one.
-	Does the published paper include a 'conflict of interest' or 'competing interests' statement? 
-	List the possible factors that might lead the experimenter to be biased in favour of finding a positive result
-	Consider the list of stages in the research process where experimenter bias could affect results: How have the researchers counteracted these?
